{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzers Basic Tutorial\n",
    "\n",
    "This Jupyter notebook will give a basic tutorial on how to use PyDeequ's Analyzers module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "import json\n",
    "import pandas as pd\n",
    "import sagemaker_pyspark\n",
    "\n",
    "import pydeequ\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using the Amazon Product Reviews dataset -- specifically the Electronics subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3a://amazon-reviews-pds/parquet/product_category=Electronics/\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     entity|            instance|               name|               value|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     Column|           review_id|       Completeness|                 1.0|\n",
      "|     Column|           review_id|ApproxCountDistinct|           3010972.0|\n",
      "|Mutlicolumn|total_votes,star_...|        Correlation|-0.03451097996538765|\n",
      "|    Dataset|                   *|               Size|           3120938.0|\n",
      "|     Column|         star_rating|               Mean|   4.036143941340712|\n",
      "|     Column|     top star_rating|         Compliance|  0.7494070692849394|\n",
      "|Mutlicolumn|total_votes,helpf...|        Correlation|  0.9936463809903863|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"review_id\")) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"review_id\")) \\\n",
    "                    .addAnalyzer(Mean(\"star_rating\")) \\\n",
    "                    .addAnalyzer(Compliance(\"top star_rating\", \"star_rating >= 4.0\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"star_rating\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"helpful_votes\")) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For more info ... look at full list of analyzers in `docs/analyzers.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}